defaults:
  - _self_
  - a01_curvature: ../analysis/a01_curvature
  - paths: ../paths

# Path where the point cloud is stored
pcd_path: data/03_labeled/SiteD_RHV_01_Labeled.txt

# Path for saving the output of the module
dst_dir: /Users/luiskremer/Code/Uni/Code_Master_RSIV/019_scanline_segmentation/data/gini_impurity

# Compression of the output point clouds (True: .npz-files, False: .txt-files)
# Compression needs more time but less space 
output_compressed: False 

# Attributes to be calculated that are taken into account for training the random forest model
attributes: ["intensity","red","green","blue","rho","slope","curvature","roughness","nx_xyz","ny_xyz","nz_xyz"]
#attributes: ["intensity","red","green","blue","rho","slope","curvature","roughness","nx_xyz","ny_xyz","nz_xyz","nx","ny","nz"]

# Scanline extraction
sce:
  # Threshold (deg) value for splitting the scanlines (in relation to the vertical movement of the scanner)
  threshold: 100
  # Bin size (meters) being used for density estimation
  bin_size: 0.5
  # Number of nearest neighbors being used for the density estimation
  k_nn: 16
  # If True, the origin of the point cloud is shifted up or down (will only affect rho and pseudo normals)
  relocate_origin: False 
  # If relocate_origin is True, the origin is shifted by this value (unit in meters; positive: up, negative: down)
  z_offset: 30 
  # If True, the "real" 3D normals are calculated using estimates of the local surface defined by a point and its neighbors
  # Will slow down the process!
  calculate_normals: False
  # Whether or not the point cloud should be saved after this intermediate processing step
  save_pcd: False

# Segmentation
scs:
  slope_threshold: 0.25 # Not being used for the moment
  # Curvature threshold (deg) at which scanlines are split into segments
  curvature_threshold: 30
  std_multiplier: 25
  neighborhood_multiplier: 2
  least_squares_method: True # If false, rise/run method is used for slope calculation
  save_pcd: False

# Subsampling
scsb:
  save_pcd: False
  save_gini_impurity: True

# Segment classification
sgcl:
  save_pcd: False

# Whether to run the classification or not
run_classification: False

# Whether to clear the logs or not
clear_logs: False

# Fixed structure of the point cloud columns (don't change)
pcd_col:
  x: 0
  y: 1
  z: 2
  intensity: 3
  red: 4
  green: 5
  blue: 6
  rho: 7 
  horiz_angle: 8
  vert_angle: 9
  point_counter: 10
  label: 11
  expected_value: 12
  expected_value_std: 13
  scanline_id: 14
  rho_diff: 15
  slope: 16
  curvature: 17
  roughness: 18
  segment_ids: 19
  nx_xyz: 20
  ny_xyz: 21
  nz_xyz: 22
  nx: 23
  ny: 24
  nz: 25

# Point cloud data column format 
# np.savetxt fmt argument is set to '%.18e' by default, resulting in large files
pcd_col_fmt:
  x: "%1.4f"
  y: "%1.4f"
  z: "%1.4f"
  intensity: "%1.6f"
  red: "%u"
  green: "%u"
  blue: "%u"
  rho: "%1.4f"
  horiz_angle: "%1.6f"
  vert_angle: "%1.6f"
  point_counter: "%u"
  label: "%u"
  expected_value: "%1.4f"
  expected_value_std: "%1.4f"
  scanline_id: "%u"
  rho_diff: "%1.4f"
  slope: "%1.4f"
  curvature: "%1.4f"
  roughness: "%1.8f"
  segment_ids: "%u"
  nx_xyz: "%1.4f"
  ny_xyz: "%1.4f"
  nz_xyz: "%1.4f"
  nx: "%1.4f"
  ny: "%1.4f"
  nz: "%1.4f"

# Fixed statistics (changing the variables will not affect the output; keep the values as they are)
statistics: ["mean","var","std","median","perc2nd","perc98th","skewness"]

# Fixed attributes
xyz_attributes: ["x_median_nn","y_median_nn","z_median_nn","x_perc2nd_nn","y_perc2nd_nn","z_perc2nd_nn","x_perc98th_nn","y_perc98th_nn","z_perc98th_nn"] 

# Will be filled in the script
filename: None









